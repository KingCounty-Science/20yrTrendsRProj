require(plyr)
require(reshape2)


LULCBind <- function(file.path, categories=NULL, minYear, maxYear) {
  # read in files
  list.with.each.file <- sapply(paste(file.path,"/", list.files(file.path, ".txt$"), sep = ''), function(y) read.delim(y, sep=",", header=TRUE), simplify = FALSE)
  # Get rid of Shape_Leng and Shape_Area that some of the .txts had
  list.2 <- lapply(list.with.each.file, function(x) {x[c(1,2,3, match("Acres", colnames(x)))]})
  #bind into dataframe
  res<-do.call("rbind.data.frame", list.2)
  loc<-str_locate(row.names(res), "_\\d{4}_")# The year in the file name needs to be surrounded by underscores
  res$year<-str_sub(row.names(res), loc[,1], loc[,2]-1)
  res$year<-str_replace(res$year, "_", "x")
  rownames(res)<-NULL
  if(!is.null(categories))
  {
    res$CODE2<-as.character(as.factor(res$GRIDCODE))
    res$CODE2<-revalue(res$CODE, categories)
    res2<-dcast(res, Name~CODE2+year, sum, value.var = "Acres")
    res3<-dcast(res, Name~year, sum, value.var="Acres")
    res4<-merge(res2, res3, by="Name")
    
    for (i in which(colnames(res4)==paste0("x",minYear)):ncol(res4)) { ## select columns "1992" onward
      print(i)
      for (column in str_subset(colnames(res4), paste0("_",colnames(res4[i])))) { ## look at the columns up until the total years start
        print(column)
        res4[ncol(res4)+1]<-res4[c(str_subset(colnames(res4), column))]/res4[i]*100
        colnames(res4)[ncol(res4)]<-paste0("per_", column)
      }
    }
    test<-str_match(colnames(res4), "(per.*)_.*")
    test<-na.omit(test[,2])
    test<-unique(test)
    for(item in unique(test)){
      res4[ncol(res4)+1]<-res4[c(str_subset(colnames(res4), paste0(item, "_x", maxYear)))] - res4[c(str_subset(colnames(res4), paste0(item, "_x", minYear)))]
      colnames(res4)[ncol(res4)]<-paste0("Change_", item)
    }
  }
  else {
    res$CODE<-as.character(as.factor(res$GRIDCODE))
    labs<-c("0" = "Background", "1"="Unclassified", "2"="High Intensity Developed", "3"="Medium Intensity Developed", "4"="Low Intensity Developed", "5"="Open Spaces Developed", "6"="Cultivated Land", "7"="Pasture-Hay", "8"="Grassland", "9"="Deciduous Forest", "10"="Evergreen Forest", "11"="Mixed Forest", "12"="Scrub-Shrub", "13"="Palustrine Forested Wetland", "14"="Palustrine Scrub-Shrub Wetland", "15"="Palustrine Emergent Wetland", "16"="Estuarine Forested Wetland", "17"="Estuarine Scrub-Shrub Wetland", "18"="Estuarine Emergent Wetland", "19"="Unconsolidated Shore", "20"="Bare Land", "21"="Water", "22"="Palustrine Aquatic Bed", "23"="Estuarine Aquatic Bed", "24"="Tundra", "25"="Snow-Ice")
    res$CODE<-revalue(res$CODE, labs)
    res2<-dcast(res, Name~CODE+year, sum, value.var = "Acres")
    res3<-dcast(res, Name~year, sum, value.var="Acres")
    res4<-merge(res2, res3, by="Name")
    year<-which(colnames(res4)==paste0("x",minYear)):ncol(res4)
    for (i in which(colnames(res4)==paste0("x",minYear)):ncol(res4)) { ## select columns "1992" onward
      print(i)
      for (column in str_subset(colnames(res4), paste0("_",colnames(res4[i])))) { ## look at the columns up until the total years start
        print(column)
        res4[ncol(res4)+1]<-res4[c(str_subset(colnames(res4), column))]/res4[i]*100
        colnames(res4)[ncol(res4)]<-paste0("per_", column)
      }
    }
    test<-str_match(colnames(res4), "(per.*)_.*")
    test<-na.omit(test[,2])
    test<-unique(test)
    for(item in unique(test)){
      res4[ncol(res4)+1]<-res4[c(str_subset(colnames(res4), paste0(item, "_x", maxYear)))] - res4[c(str_subset(colnames(res4), paste0(item, "_x", minYear)))]
      colnames(res4)[ncol(res4)]<-paste0("Change_", item)
    }
  }
  return(res4)
}
## PSSBbind joins the csv files that are generated by PSSB; originally, Steve Brady wrote the PSSBbind function to exclude any data that wasn't part of the KC ambient program (Ambient, Vashon, Boise)
## bibi is the KC ambient subset all PSSB data 
## bibi_all is all data from PSSB
pssbBind <- function(file.path, score.type = NULL, ambient = F) {
  # validate lengths of file path vector and score type vector are the same
  if (!is.null(score.type)) {
    if (length(file.path) != length(score.type)) stop("The number of score types must be equal to the number of file paths")}
  # loop through file paths, define anonymous function
  all.list <- lapply(1:length(file.path), function(x) {
    path.files <- list.files(file.path[x])
    # read in files
    list.with.each.file <- lapply(paste(file.path, list.files(file.path), sep = ''), function(y) read.delim(y, header=TRUE))
    # append id to each file individually
    if (!is.null(score.type)) {
      list.with.each.file <- lapply(list.with.each.file, function(y) {
        y$id <- score.type[x]
        y})}
    
    # bind all files from each file.path into data frames
    do.call("rbind.data.frame", list.with.each.file) 
  })
  # bind files from all file.paths into one data frame
 bibi <- do.call("rbind.data.frame", all.list) # select this and next two steps if you want the KC ambient subset

 #if (ambient == TRUE) {bibi <- droplevels(bibi[bibi$Agency=="King County - DNRP" & bibi$Project == 'Boise Ambient' |bibi$Agency=="King County - DNRP" & bibi$Project == 'Ambient Monitoring' |bibi$Agency=="King County - DNRP" & bibi$Project =='Vashon' |bibi$Agency=="King County - DNRP",])}
#test ambient only
 if (ambient == TRUE) {bibi <- droplevels(bibi[bibi$Agency=="King County - DNRP" & bibi$Project == 'Ambient Monitoring',])}
 return(bibi)
 #bibi_all<-do.call("rbind.data.frame",all.list) #select this if you want all of the PSSB data 
  
}

# Wolman<-function(data, sizeclass, D)
# {
#   sizeclass<-c(0.1, sizeclass)
#   dataWol1<-data
#   dataWol1<-cbind(dataWol1, 0) [,c(1,2,3,(length(colnames(dataWol1))+1), 4:length(colnames(dataWol1)))]
#   dataWol1<-na.omit(dataWol1)
#   dataW<-dataWol1[,-c(1:2)]
#   row.names(dataW)<-dataW[,1]
#   dataW<-dataW[,-1]
#   dataW<-t(dataW)
#   dataW[1:length(rownames(dataW)),]<-sapply(dataW[1:length(rownames(dataW)),], as.numeric)
#   as.data.frame(dataW)
#   
#   for (i in 1:ncol(dataW)) {dataW[,i]<-dataW[,i]/sum(dataW[,i])} 
#   for (i in 1:ncol(dataW)) {dataW[,i]<-cumsum(dataW[,i])} 
#   dataW<-cbind(dataW, c(sizeclass))[,c(length(colnames(dataW))+1,1:length(colnames(dataW)))]
#   
#   dataW<-dataW[,which(colSums(dataW) > 0)] 
#   D1<-data.frame(SampleID=colnames(dataW), Dis=numeric(length(colnames(dataW))))
#   
#   for (i in 2:(ncol(dataW))) { 
#     Smin<-ifelse(is.infinite(max(subset(dataW[,1], dataW[,i]<D))), 0 ,max(subset(dataW[,1], dataW[,i]<D)))
#     Smax<-dataW[ifelse((match(max(subset(dataW[,1], dataW[,i]<D)), dataW[,1])+1)==length(rownames(dataW)), (length(rownames(dataW))-1), match(max(subset(dataW[,1], dataW[,i]<D)), dataW[,1])+1),1]
#     Pmarg<-D-max(subset(dataW[,i], dataW[,i]<D))
#     Pmin<-max(subset(dataW[,i], dataW[,i]<D))
#     #Pmax<-dataW[match(max(subset(dataW[,i], dataW[,i]<D)), dataW[,i])+1,i]
#     Pmax<-dataW[length(subset(dataW[,i], dataW[,i]<D))+1,i]
#     D1[i,2]<-2^(log(Smin, base=2)+(log(Smax, base=2)-log(Smin, base = 2))*(Pmarg)/(Pmax-Pmin))
#   }
#   D1<-D1[-1,]
#   D1<-merge(dataWol1[,c(1:3)], D1, by="SampleID")
#   colnames(D1)<-paste(c("SampleID", "SITE_ID", "SAMPLE_NUMBER", paste0("D", D*100)))
#   as.data.frame(D1)
# }

Wolman<-function(data, sizeclass, D, Samplenames, start, end)
{
  sizeclass<-c(0.1, sizeclass)
  dataWol1<-data
  excess<-start-1
  tail<-ncol(dataWol1)-end
  dataWol1<-cbind(dataWol1, 0) [,c(1:excess,(ncol(dataWol1)+1), start:end)]
  dataWol1[is.na(dataWol1)]<-0
  dataW<-dataWol1
  row.names(dataW)<-dataW[,Samplenames]
  dataW<-dataW[,-c(1:excess)]
  dataW<-t(dataW)
  dataW[1:nrow(dataW),]<-sapply(dataW[1:nrow(dataW),], as.numeric)
  for (i in 1:ncol(dataW)) {dataW[,i]<-cumsum(dataW[,i])/sum(dataW[,i])} 
  dataW<-cbind(dataW, c(sizeclass))[,c(length(colnames(dataW))+1,1:length(colnames(dataW)))]
  
  dataW<-dataW[,which(colSums(dataW) > 0)] 
  D1<-data.frame(SampleID=colnames(dataW), Dis=numeric(length(colnames(dataW))))
  
  for (i in 2:(ncol(dataW))) { 
    Smin<-ifelse(is.infinite(max(subset(dataW[,1], dataW[,i]<D))), 0 ,max(subset(dataW[,1], dataW[,i]<D)))
    Smax<-dataW[ifelse((match(max(subset(dataW[,1], dataW[,i]<D)), dataW[,1])+1)==length(rownames(dataW)), (length(rownames(dataW))-1), match(max(subset(dataW[,1], dataW[,i]<D)), dataW[,1])+1),1]
    Pmarg<-D-max(subset(dataW[,i], dataW[,i]<D))
    Pmin<-max(subset(dataW[,i], dataW[,i]<D))
    #Pmax<-dataW[match(max(subset(dataW[,i], dataW[,i]<D)), dataW[,i])+1,i]
    Pmax<-dataW[length(subset(dataW[,i], dataW[,i]<D))+1,i]
    D1[i,2]<-2^(log(Smin, base=2)+(log(Smax, base=2)-log(Smin, base = 2))*(Pmarg)/(Pmax-Pmin))
  }
  D1<-D1[-1,]
  if(tail>0){
    D1<-merge(dataWol1[,c(1:excess, ((end+1):ncol(dataWol1)))], D1, by.x=Samplenames, by.y="SampleID")
  }
  else{
    D1<-merge(dataWol1[,c(1:excess)], D1, by.x=Samplenames, by.y="SampleID")
  }
  colnames(D1)[ncol(D1)]<-paste0("D", D*100)
  as.data.frame(D1)
}


taxaBind <- function(file.path) {
  
  path.files <- list.files(file.p)
  # read in files
  list.with.each.file <- lapply(paste(file.p, list.files(file.p), sep = ''), function(y) read.delim(y, header=TRUE))
  taxa<-do.call("rbind.data.frame", list.with.each.file) 
  return(taxa)
  
  
}
